{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d202f39",
   "metadata": {},
   "source": [
    "1. Model Multinomial Naive Bayes dengan CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36911a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CountVectorizer ===\n",
      "Accuracy: 0.9838565022421525\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       965\n",
      "           1       0.96      0.92      0.94       150\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.97      0.96      0.96      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[959   6]\n",
      " [ 12 138]]\n"
     ]
    }
   ],
   "source": [
    "# Import library\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# 1. Load dataset\n",
    "df = pd.read_csv(r'D:\\File untuk kuliah\\Semester-5\\Pembelajaran Mesin\\Praktek\\MachineLearning_Smst5_2025\\Week9_JS09\\Assets\\spam.csv', encoding='latin-1')\n",
    "\n",
    "# Hapus kolom tidak perlu jika ada\n",
    "df = df[['v1', 'v2']]\n",
    "df.columns = ['label', 'message']\n",
    "\n",
    "# Encode label\n",
    "df['label'] = df['label'].map({'ham': 0, 'spam': 1})\n",
    "\n",
    "# 2. Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['message'], df['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# 3. Gunakan CountVectorizer dengan stopwords\n",
    "from sklearn.feature_extraction import text\n",
    "# CountVectorizer expects stop_words to be a string ('english'), a list, or None.\n",
    "# Convert the frozenset to a list so it's accepted by newer sklearn versions.\n",
    "stop_words = list(text.ENGLISH_STOP_WORDS)\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words=stop_words)\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "# 4. Model Naive Bayes\n",
    "model_cv = MultinomialNB()\n",
    "model_cv.fit(X_train_vec, y_train)\n",
    "y_pred_cv = model_cv.predict(X_test_vec)\n",
    "\n",
    "# 5. Evaluasi\n",
    "print(\"=== CountVectorizer ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_cv))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_cv))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred_cv))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2975143d",
   "metadata": {},
   "source": [
    "2. Model Multinomial Naive Bayes dengan TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89ba6573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TF-IDF ===\n",
      "Accuracy: 0.9668161434977578\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       965\n",
      "           1       1.00      0.75      0.86       150\n",
      "\n",
      "    accuracy                           0.97      1115\n",
      "   macro avg       0.98      0.88      0.92      1115\n",
      "weighted avg       0.97      0.97      0.96      1115\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[965   0]\n",
      " [ 37 113]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# 1. TF-IDF dengan stopwords\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words=stop_words)\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# 2. Model Naive Bayes\n",
    "model_tfidf = MultinomialNB()\n",
    "model_tfidf.fit(X_train_tfidf, y_train)\n",
    "y_pred_tfidf = model_tfidf.predict(X_test_tfidf)\n",
    "\n",
    "# 3. Evaluasi\n",
    "print(\"=== TF-IDF ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_tfidf))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_tfidf))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred_tfidf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe2da40",
   "metadata": {},
   "source": [
    "3. Perbandingan Hasil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0f6cd86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Akurasi CountVectorizer: 0.9839\n",
      "Akurasi TF-IDF: 0.9668\n",
      "\n",
      "✅ CountVectorizer memberikan hasil yang lebih baik.\n"
     ]
    }
   ],
   "source": [
    "acc_cv = accuracy_score(y_test, y_pred_cv)\n",
    "acc_tfidf = accuracy_score(y_test, y_pred_tfidf)\n",
    "\n",
    "print(f\"\\nAkurasi CountVectorizer: {acc_cv:.4f}\")\n",
    "print(f\"Akurasi TF-IDF: {acc_tfidf:.4f}\")\n",
    "\n",
    "if acc_tfidf > acc_cv:\n",
    "    print(\"\\n✅ TF-IDF memberikan hasil yang lebih baik.\")\n",
    "else:\n",
    "    print(\"\\n✅ CountVectorizer memberikan hasil yang lebih baik.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77997efe",
   "metadata": {},
   "source": [
    "Kesimpulan:\n",
    "\n",
    "Berdasarkan hasil evaluasi, fitur TF-IDF biasanya memberikan akurasi lebih tinggi dibanding CountVectorizer karena memperhitungkan bobot kata yang lebih informatif dan mengurangi pengaruh kata umum (stopwords).\n",
    "\n",
    "Namun, pada dataset tertentu, CountVectorizer bisa lebih unggul jika data sangat sederhana atau berisi banyak kata berulang.\n",
    "\n",
    "Jadi, pada kasus spam.csv, jika akurasi TF-IDF > CountVectorizer, maka fitur TF-IDF adalah yang paling optimal."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
