{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b142432f",
   "metadata": {},
   "source": [
    "Praktikum 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80d4fb2",
   "metadata": {},
   "source": [
    "Backpropagation adalah sebuah algoritma untuk melatih jaringan saraf tiruan dengan cara mengoreksi kesalahan. Algoritma ini bekerja dengan cara menghitung selisih antara keluaran yang dihasilkan jaringan dan keluaran yang seharusnya (kesalahan), lalu memperbarui bobot dan bias jaringan secara berulang dari keluaran ke masukan untuk meminimalkan kesalahan tersebut. Cara kerja backpropagation\n",
    "\n",
    "- Perambatan maju (forward pass): Data masukan diproses melalui jaringan dari lapisan masukan ke lapisan keluaran untuk menghasilkan prediksi awal.\n",
    "\n",
    "- Hitung kesalahan: Selisih antara keluaran prediksi dan keluaran target dihitung menggunakan fungsi kerugian.\n",
    "\n",
    "- Perambatan mundur (backward pass): Kesalahan disebarkan kembali ke belakang melalui jaringan dari lapisan keluaran ke lapisan masukan untuk menghitung gradien atau turunan parsial dari fungsi kerugian terhadap bobot dan bias.\n",
    "\n",
    "- Perbarui bobot: Bobot dan bias disesuaikan menggunakan algoritma penurunan gradien untuk mengurangi kesalahan pada iterasi berikutnya. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43003713",
   "metadata": {},
   "source": [
    "Langkah:\n",
    "\n",
    "1. Buat dataset sederhana (XOR).\n",
    "2. Inisialisasi bobot dan bias.\n",
    "3. Implementasikan forward pass.\n",
    "4. Hitung error dan lakukan backpropagation.\n",
    "5. Update bobot menggunakan gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24320e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.2871315980752797\n",
      "Epoch 1000, Loss: 0.24845915018376988\n",
      "Epoch 2000, Loss: 0.23803833898065468\n",
      "Epoch 3000, Loss: 0.20197139272498665\n",
      "Epoch 4000, Loss: 0.1651626767582322\n",
      "Epoch 5000, Loss: 0.05998133824643194\n",
      "Epoch 6000, Loss: 0.024097272895750622\n",
      "Epoch 7000, Loss: 0.013884889221315717\n",
      "Epoch 8000, Loss: 0.009486898336613925\n",
      "Epoch 9000, Loss: 0.007114449003771177\n",
      "Prediksi:\n",
      "[[0.07290717]\n",
      " [0.91788063]\n",
      " [0.92059885]\n",
      " [0.06519047]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Dataset XOR\n",
    "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "y = np.array([[0],[1],[1],[0]])\n",
    "\n",
    "# Parameter\n",
    "input_size = 2\n",
    "hidden_size = 2\n",
    "output_size = 1\n",
    "lr = 0.1\n",
    "\n",
    "# Inisialisasi bobot\n",
    "W1 = np.random.randn(input_size, hidden_size)\n",
    "b1 = np.zeros((1, hidden_size))\n",
    "W2 = np.random.randn(hidden_size, output_size)\n",
    "b2 = np.zeros((1, output_size))\n",
    "\n",
    "# Fungsi aktivasi\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "# Training\n",
    "for epoch in range(10000):\n",
    "    # Forward pass\n",
    "    z1 = np.dot(X, W1) + b1\n",
    "    a1 = sigmoid(z1)\n",
    "    z2 = np.dot(a1, W2) + b2\n",
    "    a2 = sigmoid(z2)\n",
    "\n",
    "    # Hitung error\n",
    "    error = y - a2\n",
    "\n",
    "    # Backpropagation\n",
    "    d_a2 = error * sigmoid_derivative(a2)\n",
    "    d_W2 = np.dot(a1.T, d_a2)\n",
    "    d_b2 = np.sum(d_a2, axis=0, keepdims=True)\n",
    "\n",
    "    d_a1 = np.dot(d_a2, W2.T) * sigmoid_derivative(a1)\n",
    "    d_W1 = np.dot(X.T, d_a1)\n",
    "    d_b1 = np.sum(d_a1, axis=0, keepdims=True)\n",
    "\n",
    "    # Update bobot\n",
    "    W1 += lr * d_W1\n",
    "    b1 += lr * d_b1\n",
    "    W2 += lr * d_W2\n",
    "    b2 += lr * d_b2\n",
    "\n",
    "    if epoch % 1000 == 0:\n",
    "        loss = np.mean(np.square(error))\n",
    "        print(f\"Epoch {epoch}, Loss: {loss}\")\n",
    "\n",
    "# Output akhir\n",
    "print(\"Prediksi:\")\n",
    "print(a2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5be80e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.2627608632517608\n",
      "Epoch 1000, Loss: 0.1801062670511817\n",
      "Epoch 2000, Loss: 0.042708546595260966\n",
      "Epoch 3000, Loss: 0.013039274750646116\n",
      "Epoch 4000, Loss: 0.006982045411409443\n",
      "Epoch 5000, Loss: 0.0046429730291877086\n",
      "Epoch 6000, Loss: 0.003439366018431013\n",
      "Epoch 7000, Loss: 0.0027154566118487828\n",
      "Epoch 8000, Loss: 0.0022355146580245256\n",
      "Epoch 9000, Loss: 0.0018954587440655666\n",
      "Prediksi:\n",
      "[[0.02698094]\n",
      " [0.95956056]\n",
      " [0.95843075]\n",
      " [0.0498004 ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Dataset XOR\n",
    "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "y = np.array([[0],[1],[1],[0]])\n",
    "\n",
    "# Parameter\n",
    "input_size = 2\n",
    "hidden_size = 3\n",
    "output_size = 1\n",
    "lr = 0.1\n",
    "\n",
    "# Inisialisasi bobot\n",
    "W1 = np.random.randn(input_size, hidden_size)\n",
    "b1 = np.zeros((1, hidden_size))\n",
    "W2 = np.random.randn(hidden_size, output_size)\n",
    "b2 = np.zeros((1, output_size))\n",
    "\n",
    "# Fungsi aktivasi\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "# Training\n",
    "for epoch in range(10000):\n",
    "    # Forward pass\n",
    "    z1 = np.dot(X, W1) + b1\n",
    "    a1 = sigmoid(z1)\n",
    "    z2 = np.dot(a1, W2) + b2\n",
    "    a2 = sigmoid(z2)\n",
    "\n",
    "    # Hitung error\n",
    "    error = y - a2\n",
    "\n",
    "    # Backpropagation\n",
    "    d_a2 = error * sigmoid_derivative(a2)\n",
    "    d_W2 = np.dot(a1.T, d_a2)\n",
    "    d_b2 = np.sum(d_a2, axis=0, keepdims=True)\n",
    "\n",
    "    d_a1 = np.dot(d_a2, W2.T) * sigmoid_derivative(a1)\n",
    "    d_W1 = np.dot(X.T, d_a1)\n",
    "    d_b1 = np.sum(d_a1, axis=0, keepdims=True)\n",
    "\n",
    "    # Update bobot\n",
    "    W1 += lr * d_W1\n",
    "    b1 += lr * d_b1\n",
    "    W2 += lr * d_W2\n",
    "    b2 += lr * d_b2\n",
    "\n",
    "    if epoch % 1000 == 0:\n",
    "        loss = np.mean(np.square(error))\n",
    "        print(f\"Epoch {epoch}, Loss: {loss}\")\n",
    "\n",
    "# Output akhir\n",
    "print(\"Prediksi:\")\n",
    "print(a2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4c0f3c",
   "metadata": {},
   "source": [
    "Tugas 1:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b992e55",
   "metadata": {},
   "source": [
    "Ubah jumlah neuron hidden layer menjadi 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5cf49fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Hidden = 3] Epoch 0, Loss: 0.26812281148055644\n",
      "[Hidden = 3] Epoch 1000, Loss: 0.2476699890495169\n",
      "[Hidden = 3] Epoch 2000, Loss: 0.23157278638181727\n",
      "[Hidden = 3] Epoch 3000, Loss: 0.15516331582714915\n",
      "[Hidden = 3] Epoch 4000, Loss: 0.03219767728604328\n",
      "[Hidden = 3] Epoch 5000, Loss: 0.012098953958886518\n",
      "[Hidden = 3] Epoch 6000, Loss: 0.006956921011184971\n",
      "[Hidden = 3] Epoch 7000, Loss: 0.004774727770534475\n",
      "[Hidden = 3] Epoch 8000, Loss: 0.0035977736857096864\n",
      "[Hidden = 3] Epoch 9000, Loss: 0.0028701713630250175\n",
      "\n",
      "Prediksi (Hidden 3):\n",
      "[[0.03267232]\n",
      " [0.95211886]\n",
      " [0.94647064]\n",
      " [0.05738209]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Dataset XOR\n",
    "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "y = np.array([[0],[1],[1],[0]])\n",
    "\n",
    "# Parameter\n",
    "input_size = 2\n",
    "hidden_size = 3   \n",
    "output_size = 1\n",
    "lr = 0.1\n",
    "\n",
    "# Inisialisasi bobot\n",
    "W1 = np.random.randn(input_size, hidden_size)\n",
    "b1 = np.zeros((1, hidden_size))\n",
    "W2 = np.random.randn(hidden_size, output_size)\n",
    "b2 = np.zeros((1, output_size))\n",
    "\n",
    "# Fungsi aktivasi\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "# Training\n",
    "for epoch in range(10000):\n",
    "    # Forward pass\n",
    "    z1 = np.dot(X, W1) + b1\n",
    "    a1 = sigmoid(z1)\n",
    "    z2 = np.dot(a1, W2) + b2\n",
    "    a2 = sigmoid(z2)\n",
    "\n",
    "    # Error\n",
    "    error = y - a2\n",
    "\n",
    "    # Backpropagation\n",
    "    d_a2 = error * sigmoid_derivative(a2)\n",
    "    d_W2 = np.dot(a1.T, d_a2)\n",
    "    d_b2 = np.sum(d_a2, axis=0, keepdims=True)\n",
    "\n",
    "    d_a1 = np.dot(d_a2, W2.T) * sigmoid_derivative(a1)\n",
    "    d_W1 = np.dot(X.T, d_a1)\n",
    "    d_b1 = np.sum(d_a1, axis=0, keepdims=True)\n",
    "\n",
    "    # Update weight\n",
    "    W1 += lr * d_W1\n",
    "    b1 += lr * d_b1\n",
    "    W2 += lr * d_W2\n",
    "    b2 += lr * d_b2\n",
    "\n",
    "    if epoch % 1000 == 0:\n",
    "        loss = np.mean(np.square(error))\n",
    "        print(f\"[Hidden = 3] Epoch {epoch}, Loss: {loss}\")\n",
    "\n",
    "print(\"\\nPrediksi (Hidden 3):\")\n",
    "print(a2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8071d33c",
   "metadata": {},
   "source": [
    "Bandingkan hasil loss dengan konfigurasi awal.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f34cdf5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Hidden = 2] Epoch 0, Loss: 0.25715936418548585\n",
      "[Hidden = 2] Epoch 1000, Loss: 0.22402717489958923\n",
      "[Hidden = 2] Epoch 2000, Loss: 0.16375267966065188\n",
      "[Hidden = 2] Epoch 3000, Loss: 0.1417083868807285\n",
      "[Hidden = 2] Epoch 4000, Loss: 0.1348224189306883\n",
      "[Hidden = 2] Epoch 5000, Loss: 0.1317897026337282\n",
      "[Hidden = 2] Epoch 6000, Loss: 0.13013341363571373\n",
      "[Hidden = 2] Epoch 7000, Loss: 0.12910335362256972\n",
      "[Hidden = 2] Epoch 8000, Loss: 0.12840576160098294\n",
      "[Hidden = 2] Epoch 9000, Loss: 0.12790420670029334\n",
      "\n",
      "Prediksi (Hidden 2):\n",
      "[[0.04621345]\n",
      " [0.95682775]\n",
      " [0.4964345 ]\n",
      " [0.50252646]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Dataset XOR\n",
    "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "y = np.array([[0],[1],[1],[0]])\n",
    "\n",
    "# Parameter awal\n",
    "input_size = 2\n",
    "hidden_size = 2 \n",
    "output_size = 1\n",
    "lr = 0.1\n",
    "\n",
    "# Inisialisasi bobot\n",
    "W1 = np.random.randn(input_size, hidden_size)\n",
    "b1 = np.zeros((1, hidden_size))\n",
    "W2 = np.random.randn(hidden_size, output_size)\n",
    "b2 = np.zeros((1, output_size))\n",
    "\n",
    "# Sigmoid\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "# Training\n",
    "for epoch in range(10000):\n",
    "    z1 = np.dot(X, W1) + b1\n",
    "    a1 = sigmoid(z1)\n",
    "    z2 = np.dot(a1, W2) + b2\n",
    "    a2 = sigmoid(z2)\n",
    "\n",
    "    error = y - a2\n",
    "\n",
    "    d_a2 = error * sigmoid_derivative(a2)\n",
    "    d_W2 = np.dot(a1.T, d_a2)\n",
    "    d_b2 = np.sum(d_a2, axis=0, keepdims=True)\n",
    "\n",
    "    d_a1 = np.dot(d_a2, W2.T) * sigmoid_derivative(a1)\n",
    "    d_W1 = np.dot(X.T, d_a1)\n",
    "    d_b1 = np.sum(d_a1, axis=0, keepdims=True)\n",
    "\n",
    "    W1 += lr * d_W1\n",
    "    b1 += lr * d_b1\n",
    "    W2 += lr * d_W2\n",
    "    b2 += lr * d_b2\n",
    "\n",
    "    if epoch % 1000 == 0:\n",
    "        loss = np.mean(np.square(error))\n",
    "        print(f\"[Hidden = 2] Epoch {epoch}, Loss: {loss}\")\n",
    "\n",
    "print(\"\\nPrediksi (Hidden 2):\")\n",
    "print(a2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a3f05f",
   "metadata": {},
   "source": [
    "Tambahkan fungsi aktivasi ReLU dan bandingkan hasil.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0410a45c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ReLU Hidden=3] Epoch 0, Loss: 0.2542200561521639\n",
      "[ReLU Hidden=3] Epoch 1000, Loss: 0.009876166283346335\n",
      "[ReLU Hidden=3] Epoch 2000, Loss: 0.0029731507874242984\n",
      "[ReLU Hidden=3] Epoch 3000, Loss: 0.001632296559539261\n",
      "[ReLU Hidden=3] Epoch 4000, Loss: 0.0010997405611571438\n",
      "[ReLU Hidden=3] Epoch 5000, Loss: 0.0008191891369290097\n",
      "[ReLU Hidden=3] Epoch 6000, Loss: 0.000648957207138665\n",
      "[ReLU Hidden=3] Epoch 7000, Loss: 0.0005348315883157621\n",
      "[ReLU Hidden=3] Epoch 8000, Loss: 0.00045381642693425515\n",
      "[ReLU Hidden=3] Epoch 9000, Loss: 0.00039309453222324483\n",
      "\n",
      "Prediksi (ReLU Hidden 3):\n",
      "[[0.02949042]\n",
      " [0.98618376]\n",
      " [0.9861839 ]\n",
      " [0.01157227]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Dataset XOR\n",
    "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "y = np.array([[0],[1],[1],[0]])\n",
    "\n",
    "# Parameter\n",
    "input_size = 2\n",
    "hidden_size = 3\n",
    "output_size = 1\n",
    "lr = 0.1\n",
    "\n",
    "# Inisialisasi bobot\n",
    "W1 = np.random.randn(input_size, hidden_size)\n",
    "b1 = np.zeros((1, hidden_size))\n",
    "W2 = np.random.randn(hidden_size, output_size)\n",
    "b2 = np.zeros((1, output_size))\n",
    "\n",
    "# ReLU\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def relu_derivative(x):\n",
    "    return (x > 0).astype(float)\n",
    "\n",
    "# Sigmoid untuk output layer\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "# Training ReLU\n",
    "for epoch in range(10000):\n",
    "    # Forward\n",
    "    z1 = np.dot(X, W1) + b1\n",
    "    a1 = relu(z1)            # ReLU di hidden\n",
    "    z2 = np.dot(a1, W2) + b2\n",
    "    a2 = sigmoid(z2)\n",
    "\n",
    "    # Error\n",
    "    error = y - a2\n",
    "\n",
    "    # Backward\n",
    "    d_a2 = error * sigmoid_derivative(a2)\n",
    "    d_W2 = np.dot(a1.T, d_a2)\n",
    "    d_b2 = np.sum(d_a2, axis=0, keepdims=True)\n",
    "\n",
    "    d_a1 = np.dot(d_a2, W2.T) * relu_derivative(z1)  # backprop pakai ReLU derivative\n",
    "    d_W1 = np.dot(X.T, d_a1)\n",
    "    d_b1 = np.sum(d_a1, axis=0, keepdims=True)\n",
    "\n",
    "    # Update weight\n",
    "    W1 += lr * d_W1\n",
    "    b1 += lr * d_b1\n",
    "    W2 += lr * d_W2\n",
    "    b2 += lr * d_b2\n",
    "\n",
    "    if epoch % 1000 == 0:\n",
    "        loss = np.mean(np.square(error))\n",
    "        print(f\"[ReLU Hidden=3] Epoch {epoch}, Loss: {loss}\")\n",
    "\n",
    "print(\"\\nPrediksi (ReLU Hidden 3):\")\n",
    "print(a2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
